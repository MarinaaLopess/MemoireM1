@inproceedings{koudoro2021spatial,
  title={Spatial Named Entity Recognition in Literary Texts: What is the Influence of OCR Noise?},
  author={Koudoro-Parfait, Caroline and Lejeune, Ga{\"e}l and Roe, Glenn},
  booktitle={Proceedings of the 5th ACM SIGSPATIAL International Workshop on Geospatial Humanities},
  pages={13--21},
  year={2021}
}

@phdthesis{lejeune2023variation,
  title={De la variation linguistique et de son influence sur l'application de m{\'e}thodes de Traitement Automatique des Langues},
  author={Lejeune, Ga{\"e}l},
  year={2023},
  school={Sorbonne Universite}
}


@inproceedings{lita2003truecasing,
  title={Truecasing},
  author={Lita, Lucian Vlad and Ittycheriah, Abe and Roukos, Salim and Kambhatla, Nanda},
  booktitle={Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics},
  pages={152--159},
  year={2003}
}


@article{luoma2020exploring,
  title={Exploring cross-sentence contexts for named entity recognition with BERT},
  author={Luoma, Jouni and Pyysalo, Sampo},
  journal={arXiv preprint arXiv:2006.01563},
  year={2020}
}


@article{foley2019poetry,
  title={Poetry: Identification, entity recognition, and retrieval},
  author={Foley, John J},
  year={2019}
}


@article{zhou2022named,
  title={Named Entity Recognition of Ancient Poems Based on Albert-BiLSTM-MHA-CRF Model},
  author={Zhou, Faguo and Wang, Chao and Wang, Jipeng},
  journal={Wireless Communications and Mobile Computing},
  volume={2022},
  number={1},
  pages={6507719},
  year={2022},
  publisher={Wiley Online Library}
}


@article{van2014named,
  title={Named entity recognition and resolution for literary studies},
  author={van Dalen-Oskam, Karina and de Does, Jesse and Marx, Maarten and Sijaranamual, Isaac and Depuydt, Katrien and Verheij, Boukje and Geirnaert, Valentijn},
  journal={Computational Linguistics in the Netherlands Journal},
  volume={4},
  pages={121--136},
  year={2014}
}


@inproceedings{silva2024pportal_ner,
  title={PPORTAL\_ner: An Annotated Corpus of Portuguese Literary Entities},
  author={Silva, Mariana O and Moro, Mirella M},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={12927--12937},
  year={2024}
}


@inproceedings{10.1145/3423337.3429437,
author = {Kogkitsidou, Eleni and Gambette, Philippe},
title = {Normalisation of 16th and 17th century texts in French and geographical named entity recognition},
year = {2020},
isbn = {9781450381635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3423337.3429437},
doi = {10.1145/3423337.3429437},
abstract = {Both statistical and rule-based methods for named entity recognition are quite sensitive to the type of language used in the analysed texts. Former studies have shown for example that it was harder to detect named entities in SMS or microblog messages where words are abridged or changed to lowercase. In this article, we focus on old French texts to evaluate the impact of manual and automatic normalisation before applying five geographical named entity recognition tools, as well as an improved version of one of them, in order to help building maps displaying the locations mentioned in ancient texts. Our results show that manual normalisation leads to better results for all methods and that automatic normalisation performs differently depending on the tool used to extract geographical named entities, but with a significant improvement on most methods.},
booktitle = {Proceedings of the 4th ACM SIGSPATIAL Workshop on Geospatial Humanities},
pages = {28–34},
numpages = {7},
keywords = {text normalisation, natural language processing, geographical named entity recognition, digital humanities},
location = {Seattle, WA, USA},
series = {GeoHumanities '20}
}

@inproceedings{10.1145/3149858.3149859,
author = {Moncla, Ludovic and Gaio, Mauro and Joliveau, Thierry and Lay, Yves-Fran\c{c}ois Le},
title = {Automated Geoparsing of Paris Street Names in 19th Century Novels},
year = {2017},
isbn = {9781450354967},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3149858.3149859},
doi = {10.1145/3149858.3149859},
abstract = {Our project involves building a platform able to retrieve, map and analyze the occurrences of place names in fictional novels published between 1800 and 1914 and whose action occurs wholly or partly in Paris. We describe a proof of concept using queries made via the TXM textual analysis platform for the extraction of street names. Then, we propose a fully automatic process using the named entity recognition (NER) components of the PERDIDO platform. This paper describes some encouraging initial results obtained by combining NLP approaches (NER methods) with textometric tools for the automated geoparsing of street names.},
booktitle = {Proceedings of the 1st ACM SIGSPATIAL Workshop on Geospatial Humanities},
pages = {1–8},
numpages = {8},
keywords = {Named Entity Recognition, Geoparsing, Geographical Information Retrieval, Digital Humanities},
location = {Redondo Beach, CA, USA},
series = {GeoHumanities '17}
}

@article{bannour2024benchmark,
  title={A Benchmark Evaluation of Clinical Named Entity Recognition in French},
  author={Bannour, Nesrine and Servan, Christophe and N{\'e}v{\'e}ol, Aur{\'e}lie and Tannier, Xavier},
  journal={arXiv preprint arXiv:2403.19726},
  year={2024}
}


@inproceedings{martin-etal-2020-camembert,
    title = "{C}amem{BERT}: a Tasty {F}rench Language Model",
    author = "Martin, Louis  and
      Muller, Benjamin  and
      Ortiz Su{\'a}rez, Pedro Javier  and
      Dupont, Yoann  and
      Romary, Laurent  and
      de la Clergerie, {\'E}ric  and
      Seddah, Djam{\'e}  and
      Sagot, Beno{\^i}t",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.645/",
    doi = "10.18653/v1/2020.acl-main.645",
    pages = "7203--7219",
    abstract = "Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available models have either been trained on English data or on the concatenation of data in multiple languages. This makes practical use of such models {--}in all languages except English{--} very limited. In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks."
}



@inproceedings{le-etal-2020-flaubert-unsupervised,
    title = "{F}lau{BERT}: Unsupervised Language Model Pre-training for {F}rench",
    author = {Le, Hang  and
      Vial, Lo{\"i}c  and
      Frej, Jibril  and
      Segonne, Vincent  and
      Coavoux, Maximin  and
      Lecouteux, Benjamin  and
      Allauzen, Alexandre  and
      Crabb{\'e}, Benoit  and
      Besacier, Laurent  and
      Schwab, Didier},
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.302/",
    pages = "2479--2490",
    language = "eng",
    ISBN = "979-10-95546-34-4",
    abstract = "Language models have become a key step to achieve state-of-the art results in many different Natural Language Processing (NLP) tasks. Leveraging the huge amount of unlabeled texts nowadays available, they provide an efficient way to pre-train continuous word representations that can be fine-tuned for a downstream task, along with their contextualization at the sentence level. This has been widely demonstrated for English using contextualized representations (Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al., 2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and share FlauBERT, a model learned on a very large and heterogeneous French corpus. Models of different sizes are trained using the new CNRS (French National Centre for Scientific Research) Jean Zay supercomputer. We apply our French language models to diverse NLP tasks (text classification, paraphrasing, natural language inference, parsing, word sense disambiguation) and show that most of the time they outperform other pre-training approaches. Different versions of FlauBERT as well as a unified evaluation protocol for the downstream tasks, called FLUE (French Language Understanding Evaluation), are shared to the research community for further reproducible experiments in French NLP."
}
