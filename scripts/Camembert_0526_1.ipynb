{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Ici, « Candidat », au sens initial, peut désigner chaque fragment d’entité identifié par le modèle,tandis qu’« entité » fait plutôt référence à l’entité nommée complète, après agrégation.\n",
        "\n",
        "\n",
        "\n",
        "“candidat” 在原始意义上可以指模型识别的 每个实体片段，而“entité”更倾向于表示 完整聚合后的命名实体。"
      ],
      "metadata": {
        "id": "xRj5Oqh6-VzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import pipeline, CamembertTokenizer, TokenClassificationPipeline\n",
        "\n",
        "# === Initialisation du modèle CamemBERT spécialisé pour la reconnaissance d'entités nommées (NER) ===\n",
        "model_name = \"Jean-Baptiste/camembert-ner-with-dates\"\n",
        "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Création d'un pipeline NER avec agrégation simple (fusion des tokens associés à la même entité)\n",
        "nlp: TokenClassificationPipeline = pipeline(\n",
        "    \"ner\",\n",
        "    model=model_name,\n",
        "    tokenizer=tokenizer,\n",
        "    aggregation_strategy=\"simple\",  # Agrège les sous-tokens appartenant à une même entité\n",
        "    device=-1  # -1 = CPU, 0 = GPU (si disponible)\n",
        ")\n",
        "\n",
        "# === Texte d'exemple à analyser ===\n",
        "texte = \"Je teste spacy à Paris\"\n",
        "\n",
        "# === Tokenisation du texte : transformation en sous-unités exploitables par le modèle ===\n",
        "tokens = tokenizer.tokenize(texte)\n",
        "\n",
        "# === Application du pipeline de reconnaissance d'entités nommées ===\n",
        "ner_results = nlp(texte)\n",
        "\n",
        "# === Formatage des entités reconnues sous forme de dictionnaire simple (mot + type) ===\n",
        "liste_entitesnom = [\n",
        "    {\"mot\": ent[\"word\"], \"type\": ent[\"entity_group\"]}\n",
        "    for ent in ner_results\n",
        "]\n",
        "\n",
        "# === Affichage des résultats ===\n",
        "print(f\"Tokens        : {len(tokens)}\")               # Nombre total de tokens (sous-mots)\n",
        "print(f\"Candidats     : {len(ner_results)}\")          # Nombre d'entités reconnues par le modèle\n",
        "print(\"-\" * 20)\n",
        "print(f\"Ex_tokens     : {tokens}\")                    # Affichage des 20 premiers tokens (ou moins)\n",
        "print(f\"Ex_entités    : {liste_entitesnom}\")          # Liste des entités identifiées avec leur type\n",
        "print(f\"Ex_candidats  : {ner_results}\")               # Affichage des 20 premiers candidats (ou moins)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxDoNmvNMups",
        "outputId": "3bbe8e5f-80f4-45b3-a8d5-0ae2a07e2658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens        : 6\n",
            "Candidats     : 2\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Je', '▁teste', '▁spa', 'cy', '▁à', '▁Paris']\n",
            "Ex_entités    : [{'mot': 'spacy', 'type': 'MISC'}, {'mot': 'Paris', 'type': 'LOC'}]\n",
            "Ex_candidats  : [{'entity_group': 'MISC', 'score': np.float32(0.96689326), 'word': 'spacy', 'start': None, 'end': None}, {'entity_group': 'LOC', 'score': np.float32(0.9827497), 'word': 'Paris', 'start': None, 'end': None}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-TR6zWYr4li"
      },
      "source": [
        "### Exemple de REN pour un ouvrage dans nôtre corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/These-SCAI2023/CORPUS/blob/master/prog/Use_camemBERT.py"
      ],
      "metadata": {
        "id": "_WnlfvZ-MZ07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, TokenClassificationPipeline, CamembertTokenizer\n",
        "from itertools import chain\n",
        "\n",
        "# === Initialisation du modèle et du tokenizer CamemBERT ===\n",
        "model_name = \"Jean-Baptiste/camembert-ner-with-dates\"\n",
        "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
        "nlp: TokenClassificationPipeline = pipeline(\n",
        "    \"ner\",\n",
        "    model=model_name,\n",
        "    tokenizer=tokenizer,\n",
        "    aggregation_strategy=\"simple\",  # Agrégation des sous-tokens en entités complètes\n",
        "    device=-1  # -1 pour utiliser le CPU, 0 pour GPU si disponible\n",
        ")\n",
        "\n",
        "# === Lecture du fichier texte ===\n",
        "file_path = \"sample_data/Corpus/APPOLINAIRE_Caligrammes.txt\"\n",
        "with open(file_path, encoding=\"utf-8\") as f:\n",
        "    texte = f.read()\n",
        "\n",
        "# === Fonction pour diviser le texte en morceaux (chunks) avec chevauchement ===\n",
        "def chunk_text(text, chunk_size, overlap):\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        yield text[start:end]\n",
        "        start += chunk_size - overlap\n",
        "\n",
        "# === Conversion d'une entité brute en dictionnaire structuré ===\n",
        "def get_entity_dict(entity: dict) -> dict:\n",
        "    return {\n",
        "        \"label\": entity['entity_group'],      # Type d'entité (PER, LOC, etc.)\n",
        "        \"text\": entity['word'],               # Texte de l'entité\n",
        "        \"jalons\": [entity['start'], entity['end']]  # Indices de position dans le texte\n",
        "    }\n",
        "\n",
        "# === Traitement du texte avec le modèle NER pour extraire les entités ===\n",
        "def dico_resultats(texte, nlp: TokenClassificationPipeline, chunk_size=512, overlap=50):\n",
        "    chunks = list(chunk_text(texte, chunk_size, overlap))  # Diviser le texte\n",
        "    all_ner_results = list(chain.from_iterable([nlp(chunk) for chunk in chunks]))  # Appliquer le NER sur chaque chunk\n",
        "    entity_list = [get_entity_dict(entity) for entity in all_ner_results]  # Formatter chaque entité\n",
        "    return entity_list\n",
        "\n",
        "# === Exécution de la reconnaissance d'entités nommées ===\n",
        "liste_entitesnom = dico_resultats(texte, nlp)\n",
        "\n",
        "# === Affichage des informations utiles ===\n",
        "tokens = tokenizer.tokenize(texte)  # Tokenisation du texte (subword level)\n",
        "print(f\"Tokens        : {len(tokens)}\")  # Nombre total de tokens générés\n",
        "print(f\"Candidats     : {len(liste_entitesnom)}\")  # Nombre d'entités détectées\n",
        "print(\"-\" * 20)\n",
        "print(f\"Ex_tokens     : {tokens[:20]}\")  # Affichage des 20 premiers tokens\n",
        "ex_entites = [{\"mot\": ent[\"text\"], \"type\": ent[\"label\"]} for ent in liste_entitesnom[:20]]  # Format simplifié des entités\n",
        "print(f\"Ex_entités    : {ex_entites}\")  # Affichage des 20 premières entités extraites\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3ENmOzGK8Jr",
        "outputId": "faca35fb-2193-4067-a4f9-7b91634e01de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens        : 21295\n",
            "Candidats     : 732\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁26', '2', '▁sur', '▁26', '2']\n",
            "Ex_entités    : [{'mot': 'Texte Vues', 'type': 'MISC'}, {'mot': 'Calligrammes', 'type': 'MISC'}, {'mot': 'Guillaume Apollinaire', 'type': 'PER'}, {'mot': 'de La Fresnaye', 'type': 'PER'}, {'mot': 'Apollinaire', 'type': 'PER'}, {'mot': 'Guillaume', 'type': 'PER'}, {'mot': '(1880-1918', 'type': 'DATE'}, {'mot': '(Lausanne)', 'type': 'LOC'}, {'mot': '1952', 'type': 'DATE'}, {'mot': 'La Fresnaye, Roger de', 'type': 'PER'}, {'mot': '(1885-1925', 'type': 'DATE'}, {'mot': 'bnf.fr', 'type': 'LOC'}, {'mot': 'bnf', 'type': 'LOC'}, {'mot': 'atalogue', 'type': 'MISC'}, {'mot': 'bnf', 'type': 'ORG'}, {'mot': 'Français', 'type': 'MISC'}, {'mot': 'in', 'type': 'DATE'}, {'mot': '[Calligrammes', 'type': 'MISC'}, {'mot': 'Collection', 'type': 'MISC'}, {'mot': 'Collection du Bouquet ; 52', 'type': 'MISC'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "result = {\n",
        "    \"entites\": liste_entitesnom\n",
        "}\n",
        "with open(\"tous_entites_nommes_Camembert.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
        "    json.dump(result, json_file, indent=4, ensure_ascii=False)\n",
        "\n",
        "print(\"Résultats enregistrés dans 'tous_entites_nommes_Camembert.json'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfsrw9uVMTH3",
        "outputId": "d2e4e271-d288-49af-ec78-9ce231734aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultats enregistrés dans 'tous_entites_nommes_Camembert.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ttaiter au niveau de chaque texte"
      ],
      "metadata": {
        "id": "cPpwx8C3SxUP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hogfPoIRTWFX",
        "outputId": "a059c7da-2afe-4879-daa8-6665cacee0e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traitement du fichier : sample_data/Corpus/SAUVAGE_Tandis-que-la-terre-tourne.txt\n",
            "Tokens        : 26772\n",
            "Candidats     : 245\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁20', '4', '▁sur', '▁20', '4']\n",
            "Ex_entités    : [{'mot': 'Texte Vues', 'type': 'MISC'}, {'mot': 'Tandis que la terre tourne', 'type': 'MISC'}, {'mot': 'Cécile Sauvage', 'type': 'PER'}, {'mot': 'Sauvage, Cécile', 'type': 'PER'}, {'mot': '(1883-1927', 'type': 'DATE'}, {'mot': 'Mercure de France', 'type': 'ORG'}, {'mot': 'Paris', 'type': 'LOC'}, {'mot': '1910', 'type': 'DATE'}, {'mot': 'nf', 'type': 'ORG'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': '28/01/2020', 'type': 'DATE'}, {'mot': 'CÉCILE SA', 'type': 'PER'}, {'mot': 'UV', 'type': 'MISC'}, {'mot': 'AGE', 'type': 'PER'}, {'mot': '’andis', 'type': 'MISC'}, {'mot': 'sTOnifè POEMES — PARIS MERCVRE DE FRANGE XXVI, RVE DE CONDÉ', 'type': 'MISC'}, {'mot': 'XXVI', 'type': 'MISC'}, {'mot': 'Hollande', 'type': 'LOC'}, {'mot': 'C. S. I PLEINE LUNE', 'type': 'MISC'}]\n",
            "========================================\n",
            "Temps de traitement : 126.88 secondes\n",
            "Traitement du fichier : sample_data/Corpus/DESBORDES-VALMORE_Poesies-1820.txt\n",
            "Tokens        : 39208\n",
            "Candidats     : 837\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁2', '13', '▁sur', '▁2', '13']\n",
            "Ex_entités    : [{'mot': 'Vues', 'type': 'MISC'}, {'mot': 'Poésies de', 'type': 'MISC'}, {'mot': 'Mme Desbordes-Valmore', 'type': 'PER'}, {'mot': 'Desbordes-Valmore', 'type': 'PER'}, {'mot': 'Marceline', 'type': 'PER'}, {'mot': '(1786-1859', 'type': 'DATE'}, {'mot': 'F. Louis', 'type': 'PER'}, {'mot': 'Paris', 'type': 'LOC'}, {'mot': '1820', 'type': 'DATE'}, {'mot': 'bnf', 'type': 'ORG'}, {'mot': 'GTextes1', 'type': 'MISC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': 'Réserve', 'type': 'LOC'}, {'mot': 'P-YE-785', 'type': 'LOC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': '19/06/2013', 'type': 'DATE'}, {'mot': 'FRANÇOIS LOUIS', 'type': 'PER'}, {'mot': 'y 7 1820', 'type': 'DATE'}, {'mot': 'É L É G1E S. ELEGIES', 'type': 'ORG'}, {'mot': \"'\", 'type': 'DATE'}]\n",
            "========================================\n",
            "Temps de traitement : 183.75 secondes\n",
            "Traitement du fichier : sample_data/Corpus/NOAILLES_Derniers-vers.txt\n",
            "Tokens        : 16330\n",
            "Candidats     : 300\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁16', '6', '▁sur', '▁16', '6']\n",
            "Ex_entités    : [{'mot': 'Comtesse de Noailles', 'type': 'PER'}, {'mot': 'Noailles, Anna de', 'type': 'PER'}, {'mot': '(1876-1933', 'type': 'DATE'}, {'mot': '1933', 'type': 'DATE'}, {'mot': 'bnf.fr', 'type': 'ORG'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': 'Réserve', 'type': 'LOC'}, {'mot': 'G-YE-122', 'type': 'LOC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': '10/09/2019', 'type': 'DATE'}, {'mot': 'COMTESSE DE NOAILLES DERNIERS VERS GRASSET', 'type': 'LOC'}, {'mot': '(O DERNIERS VERS COMTESSE DE NOAILLES DERNIERS', 'type': 'LOC'}, {'mot': \"VERS ' 4 GRASSET\", 'type': 'LOC'}, {'mot': 'ANNE-JULES & HÉL<unk>NE', 'type': 'PER'}, {'mot': 'Constantin PHOTIAD<unk>S', 'type': 'PER'}, {'mot': 'En novembre 1932, après une année', 'type': 'DATE'}, {'mot': 'comtesse de Noailles', 'type': 'PER'}, {'mot': 'Poème de P amour', 'type': 'MISC'}, {'mot': 'V Honneur de souffrir', 'type': 'MISC'}, {'mot': 'Souvenirs d^un jardin d^Angleterre^', 'type': 'MISC'}]\n",
            "========================================\n",
            "Temps de traitement : 78.03 secondes\n",
            "Traitement du fichier : sample_data/Corpus/DARBOUVILLE_Poesies-et-nouvelles.txt\n",
            "Tokens        : 67413\n",
            "Candidats     : 1666\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁4', '10', '▁sur', '▁4', '10']\n",
            "Ex_entités    : [{'mot': 'Texte Vues', 'type': 'MISC'}, {'mot': 'Poésie', 'type': 'MISC'}, {'mot': \"Madame d'Arbouville\", 'type': 'PER'}, {'mot': \"Sophie d'Arbouville\", 'type': 'PER'}, {'mot': 'P. de Barante', 'type': 'PER'}, {'mot': 'Arbouville', 'type': 'PER'}, {'mot': \"Sophie d'\", 'type': 'PER'}, {'mot': '(1810-1850)', 'type': 'DATE'}, {'mot': '.', 'type': 'PER'}, {'mot': 'Amyot', 'type': 'ORG'}, {'mot': 'Paris', 'type': 'LOC'}, {'mot': '1855', 'type': 'DATE'}, {'mot': 'Barante, Prosper Brugière baron de', 'type': 'PER'}, {'mot': '(1782-1866', 'type': 'DATE'}, {'mot': 'bnf', 'type': 'ORG'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': 'Littérature', 'type': 'MISC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': '27/01/2019', 'type': 'DATE'}, {'mot': 'POÉSIES ET NOUVELLES TYPOGRAPHIE', 'type': 'MISC'}]\n",
            "========================================\n",
            "Temps de traitement : 318.21 secondes\n",
            "Traitement du fichier : sample_data/Corpus/VIVIEN_Etudes-et-preludes.txt\n",
            "Tokens        : 51280\n",
            "Candidats     : 1992\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁270', '▁sur', '▁270', '▁Nombre', '▁de']\n",
            "Ex_entités    : [{'mot': 'Texte Vues', 'type': 'MISC'}, {'mot': 'Poèmes de', 'type': 'MISC'}, {'mot': 'Renée Vivien', 'type': 'PER'}, {'mot': 'Étude', 'type': 'MISC'}, {'mot': 'Cendres et poussières', 'type': 'MISC'}, {'mot': 'Évocations', 'type': 'MISC'}, {'mot': 'Sapho', 'type': 'MISC'}, {'mot': 'La Vénus des aveugles', 'type': 'MISC'}, {'mot': 'Vivien, Renée', 'type': 'PER'}, {'mot': '(1877-1909', 'type': 'DATE'}, {'mot': 'A. Lemerre', 'type': 'ORG'}, {'mot': 'Paris', 'type': 'LOC'}, {'mot': '1923', 'type': 'DATE'}, {'mot': 'bnf.', 'type': 'ORG'}, {'mot': 'Français', 'type': 'MISC'}, {'mot': 'Français', 'type': 'MISC'}, {'mot': 'XML DTBook', 'type': 'MISC'}, {'mot': '2005-3', 'type': 'DATE'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': 'Littérature', 'type': 'MISC'}]\n",
            "========================================\n",
            "Temps de traitement : 244.84 secondes\n",
            "Traitement du fichier : sample_data/Corpus/RIMBAUD_Illuminations-et-Une-saison-en-enfer-et-Notice-Paul-Verlaine.txt\n",
            "Tokens        : 25454\n",
            "Candidats     : 552\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁16', '9', '▁sur', '▁16', '9']\n",
            "Ex_entités    : [{'mot': 'Vue', 'type': 'MISC'}, {'mot': 'les Illuminations', 'type': 'MISC'}, {'mot': 'Une Saison en Enfer', 'type': 'MISC'}, {'mot': 'Paul Verlaine', 'type': 'PER'}, {'mot': 'Une Saison en Enfer', 'type': 'MISC'}, {'mot': 'Rimbaud, Arthur', 'type': 'PER'}, {'mot': '(1854-1891', 'type': 'DATE'}, {'mot': 'L. Vanier', 'type': 'ORG'}, {'mot': 'Paris', 'type': 'LOC'}, {'mot': '1892', 'type': 'DATE'}, {'mot': 'Verlaine, Paul', 'type': 'PER'}, {'mot': '(1844-1896', 'type': 'DATE'}, {'mot': 'bnf', 'type': 'ORG'}, {'mot': '.fr', 'type': 'LOC'}, {'mot': 'Langu', 'type': 'MISC'}, {'mot': 'Français', 'type': 'MISC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': 'RESP-Z-2180', 'type': 'LOC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': '11/07/2011', 'type': 'DATE'}]\n",
            "========================================\n",
            "Temps de traitement : 120.79 secondes\n",
            "Traitement du fichier : sample_data/Corpus/LOISEAU_Fleurs-d-avril.txt\n",
            "Tokens        : 24759\n",
            "Candidats     : 403\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁1', '36', '▁sur', '▁1', '36']\n",
            "Ex_entités    : [{'mot': 'Texte Vues', 'type': 'MISC'}, {'mot': \"Fleurs d'avril\", 'type': 'MISC'}, {'mot': 'Jeanne Loiseau', 'type': 'PER'}, {'mot': 'Loiseau, Jeanne', 'type': 'PER'}, {'mot': '(1854-1921', 'type': 'DATE'}, {'mot': '(Paris)', 'type': 'LOC'}, {'mot': '1882', 'type': 'DATE'}, {'mot': 'bnf', 'type': 'ORG'}, {'mot': 'Français', 'type': 'MISC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': '23/02/2020', 'type': 'DATE'}, {'mot': 'JEANNE LOISEAU', 'type': 'PER'}, {'mot': 'Fleurs d’Avril POESIES A Fleurs d ’ Av', 'type': 'MISC'}, {'mot': '<unk>i JEANNE LOISEAU', 'type': 'PER'}, {'mot': 'Fleurs', 'type': 'MISC'}, {'mot': 'POESIES PARIS', 'type': 'MISC'}, {'mot': 'ALPHONSE LEMERRE', 'type': 'PER'}, {'mot': 'T', 'type': 'ORG'}, {'mot': 'ASSAGE', 'type': 'MISC'}]\n",
            "========================================\n",
            "Temps de traitement : 117.65 secondes\n",
            "Traitement du fichier : sample_data/Corpus/APPOLINAIRE_Caligrammes.txt\n",
            "Tokens        : 21295\n",
            "Candidats     : 732\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁26', '2', '▁sur', '▁26', '2']\n",
            "Ex_entités    : [{'mot': 'Texte Vues', 'type': 'MISC'}, {'mot': 'Calligrammes', 'type': 'MISC'}, {'mot': 'Guillaume Apollinaire', 'type': 'PER'}, {'mot': 'de La Fresnaye', 'type': 'PER'}, {'mot': 'Apollinaire', 'type': 'PER'}, {'mot': 'Guillaume', 'type': 'PER'}, {'mot': '(1880-1918', 'type': 'DATE'}, {'mot': '(Lausanne)', 'type': 'LOC'}, {'mot': '1952', 'type': 'DATE'}, {'mot': 'La Fresnaye, Roger de', 'type': 'PER'}, {'mot': '(1885-1925', 'type': 'DATE'}, {'mot': 'bnf.fr', 'type': 'LOC'}, {'mot': 'bnf', 'type': 'LOC'}, {'mot': 'atalogue', 'type': 'MISC'}, {'mot': 'bnf', 'type': 'ORG'}, {'mot': 'Français', 'type': 'MISC'}, {'mot': 'in', 'type': 'DATE'}, {'mot': '[Calligrammes', 'type': 'MISC'}, {'mot': 'Collection', 'type': 'MISC'}, {'mot': 'Collection du Bouquet ; 52', 'type': 'MISC'}]\n",
            "========================================\n",
            "Temps de traitement : 102.29 secondes\n",
            "Traitement du fichier : sample_data/Corpus/VERLAINE_Sagesse.txt\n",
            "Tokens        : 17340\n",
            "Candidats     : 491\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁1', '67', '▁sur', '▁1', '67']\n",
            "Ex_entités    : [{'mot': 'Texte Vues', 'type': 'MISC'}, {'mot': 'Sagesse', 'type': 'MISC'}, {'mot': 'Paul Verlaine', 'type': 'PER'}, {'mot': 'Verlaine', 'type': 'PER'}, {'mot': 'Paul', 'type': 'PER'}, {'mot': '(1844-1896', 'type': 'DATE'}, {'mot': 'L', 'type': 'ORG'}, {'mot': '. Vanier', 'type': 'PER'}, {'mot': 'Paris', 'type': 'LOC'}, {'mot': '1893', 'type': 'DATE'}, {'mot': 'bnf', 'type': 'ORG'}, {'mot': 'b', 'type': 'LOC'}, {'mot': 'n', 'type': 'ORG'}, {'mot': 'f', 'type': 'LOC'}, {'mot': 'fr', 'type': 'LOC'}, {'mot': 'Français', 'type': 'MISC'}, {'mot': 'Français', 'type': 'MISC'}, {'mot': '[Sagesse (français)', 'type': 'MISC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': 'Littérature', 'type': 'MISC'}]\n",
            "========================================\n",
            "Temps de traitement : 83.47 secondes\n",
            "Traitement du fichier : sample_data/Corpus/HUGO_Contemplations-T2.txt\n",
            "Tokens        : 85301\n",
            "Candidats     : 1935\n",
            "--------------------\n",
            "Ex_tokens     : ['▁Rappel', '▁de', '▁votre', '▁demande', ':', '▁Format', '▁de', '▁téléchargement', ':', '▁:', '▁Texte', '▁Vue', 's', '▁1', '▁à', '▁2', '46', '▁sur', '▁2', '46']\n",
            "Ex_entités    : [{'mot': 'Texte Vues', 'type': 'MISC'}, {'mot': \"Aujourd'hui, 1843-1856\", 'type': 'DATE'}, {'mot': 'Victor Hugo', 'type': 'PER'}, {'mot': 'Hugo', 'type': 'PER'}, {'mot': 'Victor', 'type': 'PER'}, {'mot': '(1802-1885', 'type': 'DATE'}, {'mot': '(Paris)', 'type': 'LOC'}, {'mot': '1856', 'type': 'DATE'}, {'mot': 'bnf', 'type': 'ORG'}, {'mot': 'Français', 'type': 'MISC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': 'Bibliothèque nationale de France', 'type': 'LOC'}, {'mot': '01/07/2008', 'type': 'DATE'}, {'mot': \"LES CONTEMPLATIONS l'Ai! VICTOR HUGO TOME\", 'type': 'MISC'}, {'mot': '1843', 'type': 'DATE'}, {'mot': '56', 'type': 'DATE'}, {'mot': 'PARIS', 'type': 'LOC'}, {'mot': '1856', 'type': 'DATE'}, {'mot': 'LEIPZIG', 'type': 'PER'}, {'mot': 'CHEZ WOLEGANG GERHARD', 'type': 'PER'}]\n",
            "========================================\n",
            "Temps de traitement : 396.79 secondes\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "from transformers import pipeline, TokenClassificationPipeline, CamembertTokenizer\n",
        "from itertools import chain\n",
        "from tqdm import tqdm\n",
        "\n",
        "# === Initialisation du modèle CamemBERT ===\n",
        "model_name = \"Jean-Baptiste/camembert-ner-with-dates\"\n",
        "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
        "nlp: TokenClassificationPipeline = pipeline(\n",
        "    \"ner\",\n",
        "    model=model_name,\n",
        "    tokenizer=tokenizer,\n",
        "    aggregation_strategy=\"simple\",\n",
        "    device=-1  # CPU\n",
        ")\n",
        "\n",
        "# === Fonction : diviser le texte en morceaux exploitables par le modèle ===\n",
        "def chunk_text(text, chunk_size=512, overlap=50):\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        yield text[start:end]\n",
        "        start += chunk_size - overlap\n",
        "\n",
        "# === Fonction : transformer une entité en format structuré ===\n",
        "def get_entity_dict(entity: dict) -> dict:\n",
        "    return {\n",
        "        \"label\": entity['entity_group'],\n",
        "        \"text\": entity['word'],\n",
        "        \"jalons\": [entity['start'], entity['end']]\n",
        "    }\n",
        "\n",
        "# === Fonction : exécuter le NER sur un texte donné ===\n",
        "def dico_resultats(texte, nlp: TokenClassificationPipeline, chunk_size=512, overlap=50):\n",
        "    chunks = list(chunk_text(texte, chunk_size, overlap))\n",
        "    all_ner_results = list(chain.from_iterable([nlp(chunk) for chunk in chunks]))\n",
        "    return [get_entity_dict(entity) for entity in all_ner_results]\n",
        "\n",
        "# === Créer un dossier pour les fichiers JSON (si non existant) ===\n",
        "os.makedirs(\"output_json\", exist_ok=True)\n",
        "\n",
        "# === Traitement de chaque fichier texte ===\n",
        "for path_fichier in glob.glob(\"sample_data/Corpus/*.txt\"):\n",
        "    file_name = os.path.basename(path_fichier)\n",
        "    print(f\"Traitement du fichier : {file_name}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    with open(path_fichier, \"r\", encoding=\"utf-8\") as f:\n",
        "        texte = f.read().strip()\n",
        "\n",
        "    # Extraction des entités\n",
        "    liste_entitesnom = dico_resultats(texte, nlp)\n",
        "\n",
        "    # Tokenisation\n",
        "    tokens = tokenizer.tokenize(texte)\n",
        "\n",
        "    # === Affichage dans la console ===\n",
        "    print(f\"Tokens        : {len(tokens)}\")\n",
        "    print(f\"Candidats     : {len(liste_entitesnom)}\")\n",
        "    print(\"-\" * 20)\n",
        "    print(f\"Ex_tokens     : {tokens[:20]}\")\n",
        "    ex_entites = [{\"mot\": ent[\"text\"], \"type\": ent[\"label\"]} for ent in liste_entitesnom[:20]]\n",
        "    print(f\"Ex_entités    : {ex_entites}\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Temps de traitement : {time.time() - start_time:.2f} secondes\")\n",
        "\n",
        "    # === Sauvegarde en JSON : uniquement {mot, type} ===\n",
        "    entites_simplifiees = [{\"mot\": ent[\"text\"], \"type\": ent[\"label\"]} for ent in liste_entitesnom]\n",
        "    result = {\"entites\": entites_simplifiees}\n",
        "\n",
        "    nom_fichier_json = file_name.replace(\".txt\", \"_entites.json\")\n",
        "    output_path = f\"sample_data/output_json/{nom_fichier_json}\"\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f_json:\n",
        "        json.dump(result, f_json, indent=4, ensure_ascii=False)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
