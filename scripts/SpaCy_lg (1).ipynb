{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxoPVYjdm4Qi7HcnIO6/qF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmXQDnhFQNdA","executionInfo":{"status":"ok","timestamp":1745522991740,"user_tz":-120,"elapsed":22916,"user":{"displayName":"Marina “Nina” Lopes","userId":"16067133594074874086"}},"outputId":"51f27c20-b7f7-4ebe-a443-bbf5dd4d43ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!python3 -m spacy download fr_core_news_lg\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ig2dBVjsQlIJ","executionInfo":{"status":"ok","timestamp":1745523033397,"user_tz":-120,"elapsed":38433,"user":{"displayName":"Marina “Nina” Lopes","userId":"16067133594074874086"}},"outputId":"6191007e-9251-4abe-eec7-33f11551c9c9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fr-core-news-lg==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_lg-3.8.0/fr_core_news_lg-3.8.0-py3-none-any.whl (571.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.8/571.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fr-core-news-lg\n","Successfully installed fr-core-news-lg-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_lg')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","import spacy\n","from tqdm import tqdm\n","\n","\n","nlp = spacy.load('fr_core_news_lg')\n","\n","base_path = \"/content/drive/MyDrive/Poemes/\"\n","dic = {}\n","\n","entites_par_auteur = {}\n","tokens_par_auteur = {}\n","\n","for auteur in tqdm(os.listdir(base_path), desc=\"Auteurs\", unit=\"auteur\"):\n","    auteur_path = os.path.join(base_path, auteur)\n","\n","    if os.path.isdir(auteur_path):\n","        entites_par_auteur[auteur] = 0\n","        tokens_par_auteur[auteur] = 0\n","\n","        for poeme in tqdm(os.listdir(auteur_path), desc=f\"Poèmes de {auteur}\", unit=\"poème\", leave=False):\n","            if poeme.endswith(\".txt\"):\n","                file_path = os.path.join(auteur_path, poeme)\n","\n","                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n","                    contenu = f.read()\n","\n","                doc = nlp(contenu)\n","\n","                nb_tokens = len([token for token in doc if not token.is_space])\n","                nb_entites = len(doc.ents)\n","\n","                tokens_par_auteur[auteur] += nb_tokens\n","                entites_par_auteur[auteur] += nb_entites\n","\n","                dic[poeme] = {\n","                    \"auteur\": auteur,\n","                    \"nombre de tokens\": nb_tokens,\n","                    \"nombre d'entités nommées\": nb_entites,\n","                    \"entités nommées\": [{\"texte\": ent.text, \"type\": ent.label_} for ent in doc.ents],\n","                }\n","\n","json_file_path = \"/content/drive/MyDrive/resultat_lg_spacy.json\"\n","with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n","    json.dump(dic, json_file, ensure_ascii=False, indent=4)\n","\n","print(\"\\nNombre total de tokens par auteur :\")\n","for auteur, nb_tokens in tokens_par_auteur.items():\n","    print(f\"- {auteur}: {nb_tokens} tokens\")\n","\n","print(\"\\nNombre total d'entités nommées par auteur :\")\n","for auteur, nb_entites in entites_par_auteur.items():\n","    print(f\"- {auteur}: {nb_entites} entités nommées\")\n","\n","total_tokens = sum(tokens_par_auteur.values())\n","total_entites = sum(entites_par_auteur.values())\n","\n","print(f\"\\nNombre total de tokens dans tous les poèmes : {total_tokens}\")\n","print(f\"Nombre total d'entités nommées dans tous les poèmes : {total_entites}\")\n","\n","print(f\"\\nAnalyse terminée. Résultats enregistrés dans {json_file_path}.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CrTniL6hQsNx","executionInfo":{"status":"ok","timestamp":1745523188891,"user_tz":-120,"elapsed":81408,"user":{"displayName":"Marina “Nina” Lopes","userId":"16067133594074874086"}},"outputId":"35028d75-1f75-4469-accf-a81730399fb7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Auteurs:   0%|          | 0/10 [00:00<?, ?auteur/s]\n","Poèmes de Appolinaire:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Appolinaire: 100%|██████████| 1/1 [00:05<00:00,  5.60s/poème]\u001b[A\n","Auteurs:  10%|█         | 1/10 [00:05<00:53,  5.97s/auteur]\n","Poèmes de Darbourville:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Darbourville: 100%|██████████| 1/1 [00:13<00:00, 13.05s/poème]\u001b[A\n","Auteurs:  20%|██        | 2/10 [00:19<01:21, 10.14s/auteur]\n","Poèmes de Desbordes:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Desbordes: 100%|██████████| 1/1 [00:05<00:00,  5.66s/poème]\u001b[A\n","Auteurs:  30%|███       | 3/10 [00:24<00:56,  8.10s/auteur]\n","Poèmes de Hugo:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Hugo: 100%|██████████| 1/1 [00:15<00:00, 15.48s/poème]\u001b[A\n","Auteurs:  40%|████      | 4/10 [00:40<01:06, 11.02s/auteur]\n","Poèmes de Loiseau:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Loiseau: 100%|██████████| 1/1 [00:04<00:00,  4.43s/poème]\u001b[A\n","Auteurs:  50%|█████     | 5/10 [00:44<00:43,  8.65s/auteur]\n","Poèmes de Noialles:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Noialles: 100%|██████████| 1/1 [00:02<00:00,  2.91s/poème]\u001b[A\n","Auteurs:  60%|██████    | 6/10 [00:47<00:26,  6.70s/auteur]\n","Poèmes de Rimbaud:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Rimbaud: 100%|██████████| 1/1 [00:04<00:00,  4.49s/poème]\u001b[A\n","Auteurs:  70%|███████   | 7/10 [00:52<00:17,  5.98s/auteur]\n","Poèmes de Sauvage:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Sauvage: 100%|██████████| 1/1 [00:05<00:00,  5.72s/poème]\u001b[A\n","Auteurs:  80%|████████  | 8/10 [00:57<00:11,  5.90s/auteur]\n","Poèmes de Verlaine:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Verlaine: 100%|██████████| 1/1 [00:02<00:00,  2.79s/poème]\u001b[A\n","Auteurs:  90%|█████████ | 9/10 [01:00<00:04,  4.93s/auteur]\n","Poèmes de Vivien:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n","Poèmes de Vivien: 100%|██████████| 1/1 [00:08<00:00,  8.37s/poème]\u001b[A\n","Auteurs: 100%|██████████| 10/10 [01:08<00:00,  6.90s/auteur]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Nombre total de tokens par auteur :\n","- Appolinaire: 16834 tokens\n","- Darbourville: 55910 tokens\n","- Desbordes: 31130 tokens\n","- Hugo: 66426 tokens\n","- Loiseau: 20742 tokens\n","- Noialles: 12901 tokens\n","- Rimbaud: 20809 tokens\n","- Sauvage: 20854 tokens\n","- Verlaine: 14257 tokens\n","- Vivien: 39110 tokens\n","\n","Nombre total d'entités nommées par auteur :\n","- Appolinaire: 1171 entités nommées\n","- Darbourville: 2712 entités nommées\n","- Desbordes: 1936 entités nommées\n","- Hugo: 3746 entités nommées\n","- Loiseau: 1251 entités nommées\n","- Noialles: 874 entités nommées\n","- Rimbaud: 670 entités nommées\n","- Sauvage: 1353 entités nommées\n","- Verlaine: 1067 entités nommées\n","- Vivien: 3382 entités nommées\n","\n","Nombre total de tokens dans tous les poèmes : 298973\n","Nombre total d'entités nommées dans tous les poèmes : 18162\n","\n","Analyse terminée. Résultats enregistrés dans /content/drive/MyDrive/resultat_lg_spacy.json.\n"]}]}]}