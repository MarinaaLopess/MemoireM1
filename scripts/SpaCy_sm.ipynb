{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwK5V9kePTEa",
        "outputId": "cbfd2bf8-29d5-4e1c-d1fd-d1cf0431e69c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy download fr_core_news_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcOaPzD4PYIN",
        "outputId": "8344e885-a70c-4f69-c718-cc6310f07b2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fr-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.load('fr_core_news_sm')\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/Poemes/\"\n",
        "dic = {}\n",
        "\n",
        "entites_par_auteur = {}\n",
        "tokens_par_auteur = {}\n",
        "\n",
        "for auteur in tqdm(os.listdir(base_path), desc=\"Auteurs\", unit=\"auteur\"):\n",
        "    auteur_path = os.path.join(base_path, auteur)\n",
        "\n",
        "    if os.path.isdir(auteur_path):\n",
        "        entites_par_auteur[auteur] = 0\n",
        "        tokens_par_auteur[auteur] = 0\n",
        "\n",
        "        for poeme in tqdm(os.listdir(auteur_path), desc=f\"Poèmes de {auteur}\", unit=\"poème\", leave=False):\n",
        "            if poeme.endswith(\".txt\"):\n",
        "                file_path = os.path.join(auteur_path, poeme)\n",
        "\n",
        "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    contenu = f.read()\n",
        "\n",
        "                doc = nlp(contenu)\n",
        "\n",
        "                nb_tokens = len([token for token in doc if not token.is_space])\n",
        "                nb_entites = len(doc.ents)\n",
        "\n",
        "\n",
        "                tokens_par_auteur[auteur] += nb_tokens\n",
        "                entites_par_auteur[auteur] += nb_entites\n",
        "\n",
        "                dic[poeme] = {\n",
        "                    \"auteur\": auteur,\n",
        "                    \"nombre de tokens\": nb_tokens,\n",
        "                    \"nombre d'entités nommées\": nb_entites,\n",
        "                    \"entités nommées\": [{\"texte\": ent.text, \"type\": ent.label_} for ent in doc.ents],\n",
        "                }\n",
        "\n",
        "json_file_path = \"/content/drive/MyDrive/resultat_sm_spacy.json\"\n",
        "with open(json_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "    json.dump(dic, json_file, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"\\nNombre total de tokens par auteur :\")\n",
        "for auteur, nb_tokens in tokens_par_auteur.items():\n",
        "    print(f\"- {auteur}: {nb_tokens} tokens\")\n",
        "\n",
        "print(\"\\nNombre total d'entités nommées par auteur :\")\n",
        "for auteur, nb_entites in entites_par_auteur.items():\n",
        "    print(f\"- {auteur}: {nb_entites} entités nommées\")\n",
        "\n",
        "total_tokens = sum(tokens_par_auteur.values())\n",
        "total_entites = sum(entites_par_auteur.values())\n",
        "\n",
        "print(f\"\\nNombre total de tokens dans tous les poèmes : {total_tokens}\")\n",
        "print(f\"Nombre total d'entités nommées dans tous les poèmes : {total_entites}\")\n",
        "\n",
        "print(f\"\\nAnalyse terminée. Résultats enregistrés dans {json_file_path}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhX8nzd4PZ92",
        "outputId": "eb54ad77-2747-4951-d7b1-12ed72a17100"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Auteurs:   0%|          | 0/10 [00:00<?, ?auteur/s]\n",
            "Poèmes de Appolinaire:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Appolinaire: 100%|██████████| 1/1 [00:06<00:00,  6.21s/poème]\u001b[A\n",
            "Auteurs:  10%|█         | 1/10 [00:06<00:58,  6.50s/auteur]\n",
            "Poèmes de Darbourville:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Darbourville: 100%|██████████| 1/1 [00:12<00:00, 12.59s/poème]\u001b[A\n",
            "Auteurs:  20%|██        | 2/10 [00:19<01:20, 10.09s/auteur]\n",
            "Poèmes de Desbordes:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Desbordes: 100%|██████████| 1/1 [00:07<00:00,  7.76s/poème]\u001b[A\n",
            "Auteurs:  30%|███       | 3/10 [00:26<01:03,  9.03s/auteur]\n",
            "Poèmes de Hugo:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Hugo: 100%|██████████| 1/1 [00:16<00:00, 16.01s/poème]\u001b[A\n",
            "Auteurs:  40%|████      | 4/10 [00:42<01:10, 11.79s/auteur]\n",
            "Poèmes de Loiseau:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Loiseau: 100%|██████████| 1/1 [00:04<00:00,  4.47s/poème]\u001b[A\n",
            "Auteurs:  50%|█████     | 5/10 [00:47<00:45,  9.16s/auteur]\n",
            "Poèmes de Noialles:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Noialles: 100%|██████████| 1/1 [00:04<00:00,  4.19s/poème]\u001b[A\n",
            "Auteurs:  60%|██████    | 6/10 [00:51<00:29,  7.48s/auteur]\n",
            "Poèmes de Rimbaud:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Rimbaud: 100%|██████████| 1/1 [00:04<00:00,  4.72s/poème]\u001b[A\n",
            "Auteurs:  70%|███████   | 7/10 [00:56<00:19,  6.58s/auteur]\n",
            "Poèmes de Sauvage:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Sauvage: 100%|██████████| 1/1 [00:04<00:00,  4.47s/poème]\u001b[A\n",
            "Auteurs:  80%|████████  | 8/10 [01:00<00:11,  5.91s/auteur]\n",
            "Poèmes de Verlaine:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Verlaine: 100%|██████████| 1/1 [00:04<00:00,  4.42s/poème]\u001b[A\n",
            "Auteurs:  90%|█████████ | 9/10 [01:05<00:05,  5.45s/auteur]\n",
            "Poèmes de Vivien:   0%|          | 0/1 [00:00<?, ?poème/s]\u001b[A\n",
            "Poèmes de Vivien: 100%|██████████| 1/1 [00:07<00:00,  7.47s/poème]\u001b[A\n",
            "Auteurs: 100%|██████████| 10/10 [01:12<00:00,  7.27s/auteur]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nombre total de tokens par auteur :\n",
            "- Appolinaire: 16834 tokens\n",
            "- Darbourville: 55910 tokens\n",
            "- Desbordes: 31130 tokens\n",
            "- Hugo: 66426 tokens\n",
            "- Loiseau: 20742 tokens\n",
            "- Noialles: 12901 tokens\n",
            "- Rimbaud: 20809 tokens\n",
            "- Sauvage: 20854 tokens\n",
            "- Verlaine: 14257 tokens\n",
            "- Vivien: 39110 tokens\n",
            "\n",
            "Nombre total d'entités nommées par auteur :\n",
            "- Appolinaire: 1260 entités nommées\n",
            "- Darbourville: 4087 entités nommées\n",
            "- Desbordes: 2640 entités nommées\n",
            "- Hugo: 3753 entités nommées\n",
            "- Loiseau: 1513 entités nommées\n",
            "- Noialles: 1083 entités nommées\n",
            "- Rimbaud: 753 entités nommées\n",
            "- Sauvage: 1552 entités nommées\n",
            "- Verlaine: 1067 entités nommées\n",
            "- Vivien: 3331 entités nommées\n",
            "\n",
            "Nombre total de tokens dans tous les poèmes : 298973\n",
            "Nombre total d'entités nommées dans tous les poèmes : 21039\n",
            "\n",
            "Analyse terminée. Résultats enregistrés dans /content/drive/MyDrive/resultat_sm_spacy.json.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
